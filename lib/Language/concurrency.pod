=begin pod

=TITLE Concurrency

=SUBTITLE Concurrency and Asynchronous Programming

In common with most modern programming languages Perl 6 is designed
to support concurrency (allowing more than one thing to happen at the
same time,) and asynchronous programming (sometime called event driven
or reactive programming - that is an event or change in some part of a
program may lead to an event or change in some other part of the program
asynchronously to the program flow. )

The aim of the Perl concurrency design is to provide a consistent interface
regardless of how a virtual may machine may implement it for a particular
operating system, through layers of facilities as described below.

=begin comment

I'm not quite clear which specific features should be included below

hyper-operators, autothreading junctions?

=end comment

Additionally certain Perl features may implicitly operate in am asynchronous
fashion, so in order to ensure predictable interoperation with these features
user code should, where possible, avoid the lower level concurrency APIs 
(i.e. L<Thread> and L<Scheduler> ) and use the higher-level interfaces.

=head2 Threads

The lowest level interface for concurrency is provided by L<Thread>. A
thread can be thought of as a piece of code that may eventually be run
on a processor, the arrangement for which is made almost entirely by the
virtual machine and/or operating system. Threads should be considered,
for all intents, largely un-managed and should be avoided in user code.

A thread can either be created and then actually run later:

    my $thread = Thread.new(code => { for  1 .. 10  -> $v { say $v }});
    # ...
    $thread.run;

Or can be created and run at a single invocation:

    my $thread = Thread.start({ for  1 .. 10  -> $v { say $v }});

In both cases the completion of the code encapsulated by the L<Thread>
object can be waited on with the C<finish> method which will block until
the thread completes:

    $thread.finish;

Beyond that there are  no further facilities for synchronization or resource
sharing which is largely why it should be emphasised that threads are unlikely
to be useful directly in user code.



=head2 Schedulers

The next level of the concurrency API is that supplied by classes that
provide the interface defined by the role L<Scheduler>.  The intent
of the scheduler interface is to provide a mechanism to determine which
resources to use to run a particular task and when to run it. The majority
of the higher level concurrency APIs are built upon a scheduler and it
may not be necessary for user code to use them at all, although some
methods such as those found in L<Proc::Async>, L<Promise> and L<Supply>
allow you to explicitly supply a scheduler.

The current default global scheduler is available in the variable
C<$*SCHEDULER>.

The primary interface of a scheduler (indeed the only method required
by the L<Scheduler> interface) is the C<cue> method:

     method cue(:&code, Instant :$at, :$in, :$every, :$times = 1; :&catch)

This will schedule the L<Callable> in C<&code> to be executed in the
manner determined by the adverbs (as documented in L<Scheduler>) using
the execution scheme as implemented by the scheduler. For example:

     my $i = 0;
     my $cancellation = $*SCHEDULER.cue({ say $i++}, every => 2 );
     sleep 20;

Assuming that the C<$*SCHEDULER> hasn't been changed from the default,
will print the numbers 0 to 10 approximately (i.e with operating system
scheduling tolerances) every two seconds.  In this case the code will
be scheduled to run until the program ends normally, however the method
returns a L<Cancellation> object which can be used to cancel the scheduled
execution before normal completion:

     my $i = 0;
     my $cancellation = $*SCHEDULER.cue({ say $i++}, every => 2 );
     sleep 10;
     $cancellation.cancel;
     sleep 10;

should only output 0 to 5,

Despite the apparent advantage the L<Scheduler> interface provides over
that of L<Thread> all of functionality is available through higher level
interfaces and it shouldn't be necessary to use a scheduler directly,
except perhaps in the cases mentioned above where a scheduler can be
supplied explicitly to certain methods.

A library may wish to provide an alternative scheduler implementation if
it has special requirements, for instance a UI library may want all code
to be run within a single UI thread, or some custom priority mechanism
may be required, however the implementations provided as standard and
described below should suffice for most user code.

=head3 ThreadPoolScheduler

The L<ThreadPoolScheduler> is the default scheduler, it maintains a pool
of threads that are allocated on demand, creating new ones as necessary up
to maximum number given as a parameter when the scheduler object was created
(the default is 16.)  If the maximum is exceeded then C<cue> may queue the
code until such time as a thread becomes available.

Rakudo allows the maximum number of threads allowed in the default scheduler
to be set by the environment variable C<RAKUDO_MAX_THREADS> at the time
the program is started.

=head3 CurrentThreadScheduler

The L<CurrentThreadScheduler> is a very simple scheduler that will always
schedule code to be run straight away on the current thread. The implication
is that C<cue> on this scheduler will block until the code finishes
execution, limiting its utility to certain special cases such as testing.

=begin comment

=head2 promises

=head3 start

=head3 await

=head2 supplies

=head3 tap

=head3 emit

=head2 channels

=end comment



=end pod
